# pytorch-note
> 源代码名称加入nn为pytorch官方实现，否则为从0开始实现自己实现
## basis
1. 线性回归实现-linear_regression
2. softmax回归实现-softmax_regression
3. 多层感知机实现-multilayer_perceptron
4. 欠拟合和过拟合-underfitting_overfitting
5. 权重衰减实现-weight_decay
6. 丢弃法实现-dropout
## network
1. 神经网络基础-network_basis
2. GPU基本操作-gpu_basis
3.  卷积神经网络实现-convolutional_neural_network
    填充和步幅-padding_stride
    多个输入通道和输出通道-multiple_input_output_channels
    池化层-pooling_layer 
    LeNet实现-lenet
    AlexNet实现-alexnet
    VGG实现-vgg
    NiN实现-nin
    GoogLeNet实现-googlenet
    批量归一化-batch_normalization
    残差网络-resnet
4. 数据增强-data_augmentation
5. 微调-fine_tuning
6.  目标检测和物体检测-object_detection
    锚框-anchor_box
    区域卷积神经网络-rcnn
    SSD实现-ssd
7.  语义分割-semantic_segmentation
    转置卷积-transposed_convolution
    全连接神经网络全卷积网络-fcn
    样式迁移-style_transfer
8.  序列模型-sequence_model
    文本预处理-text_preprocessing
    语言模型-language_model 
    循环神经网络-rnn
    门控循环单元-gru
    长短期记忆网络-lstm
    深度循环神经网络-deep_rnn
    双向循环神经网络-bidirectional_rnn
9.  编码器解码器-encoder_decoder
    序列到序列学习-seq2seq
    注意力机制-attention_mechanism
    使用注意力机制的seq2seq-attention_seq2seq
    自注意力机制-self_attention
